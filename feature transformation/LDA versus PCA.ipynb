{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA versus PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn's version of PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with supervised machine learning and attempt to build a classifier to recognize the species of flower given the four quantitative flower traits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA module to keep a single component\n",
    "single_pca = PCA(n_components=1)\n",
    "\n",
    "# Create a LDA module to keep a single component\n",
    "single_lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# Instantiate a KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803921568627452"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a cross validation on the KNN without any feature transformation\n",
    "knn_average = cross_val_score(knn, X, y).mean()\n",
    "\n",
    "# This is a baseline accuracy. If we did nothing, KNN on its own achieves a 98% accuracy\n",
    "knn_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy to beat is 98.04%. Let's use our LDA, which keeps only the most powerful component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9673202614379085"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pipeline = Pipeline([('lda', single_lda), ('knn', knn)])\n",
    "lda_average = cross_val_score(lda_pipeline, X, y).mean()\n",
    "\n",
    "# better prediction accuracy than PCA by a good amount, but not as good as original\n",
    "lda_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that only using a single linear discriminant isn't enough to beat our baseline accuracy. Let us now try the PCA. Our hypothesis here is that the PCA will not outperform the LDA for the sole reason that the PCA is not trying to optimize for class separation as LDA is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8941993464052288"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pipeline that performs PCA\n",
    "pca_pipeline = Pipeline([('pca', single_pca), ('knn', knn)])\n",
    "\n",
    "pca_average = cross_val_score(pca_pipeline, X, y).mean()\n",
    "\n",
    "pca_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely the worst so far. \n",
    "It is worth exploring whether adding another LDA component will help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803921568627452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try LDA with 2 components\n",
    "lda_pipeline = Pipeline([('lda', LinearDiscriminantAnalysis(n_components=2)),\n",
    "                        ('knn', knn)])\n",
    "lda_average = cross_val_score(lda_pipeline, X, y).mean()\n",
    "\n",
    "# Just as good as using original data\n",
    "lda_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With two components, we are able to achieve the original accuracy! This is great, but we want to do better than our baseline. Let's see if a feature selection module from the last chapter can help us. Let's import and use the SelectKBest module and see if statistical feature selection would best our LDA module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 best feature has accuracy: 0.9538398692810457\n",
      "2 best feature has accuracy: 0.9607843137254902\n",
      "3 best feature has accuracy: 0.9738562091503268\n"
     ]
    }
   ],
   "source": [
    "# compare our feature transformation tools to a feature selection tool\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# try all possible values for k, excluding keeping all columns\n",
    "for k in [1, 2, 3]:\n",
    "    select_pipeline = Pipeline([('select', SelectKBest(k=k)),  ('knn', knn)])\n",
    "    # cross validate the pipeline\n",
    "    select_average = cross_val_score(select_pipeline, X, y).mean()\n",
    "    print(k, \"best feature has accuracy:\", select_average)\n",
    "\n",
    "# LDA is even better than the best selectkbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our LDA with two components is so far winning. In production, it is quite common to use both unsupervised and supervised feature transformations. Let's set up a GridSearch module to find the best combination across:\n",
    "\n",
    "-  Scaling data (with or without mean/std)\n",
    "-  PCA components\n",
    "-  LDA components\n",
    "-  KNN neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block is going to set up a function called get_best_model_and_accuracy which will take in a model (scikit-learn pipeline or other), a parameter grid in the form of a dictionary, our X and y datasets, and output the result of the grid search module. The output will be the model's best performance (in terms of accuracy), the best parameters that led to the best performance, the average time it took to fit, and the average time it took to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_and_accuracy(model, params, X, y):\n",
    "    grid = GridSearchCV(model, # the model to grid search\n",
    "                        params, # the parameter set to try\n",
    "                        error_score=0.) # if a parameter set raises an error, continue and set the performance as a big, fat 0\n",
    "\n",
    "    grid.fit(X, y) # fit the model and parameters\n",
    "    # our classical metric for performance\n",
    "    print \"Best Accuracy: {}\".format(grid.best_score_)\n",
    "    # the best parameters that caused the best accuracy\n",
    "    print \"Best Parameters: {}\".format(grid.best_params_)\n",
    "    # the average time it took a model to fit to the data (in seconds)\n",
    "    avg_time_fit = round(grid.cv_results_['mean_fit_time'].mean(), 3)\n",
    "    print \"Average Time to Fit (s): {}\".format(avg_time_fit)\n",
    "    # the average time it took a model to predict out of sample data (in seconds)\n",
    "    # this metric gives us insight into how this model will perform in real-time analysis\n",
    "    print \"Average Time to Score (s): {}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_and_accuracy(model, params, X, y):\n",
    "    grid = GridSearchCV(model, # the model to grid search\n",
    "                       params, # the parameter set to try\n",
    "                       error_score=0.) # if a parameter set raises an error, continue and set the performance as a big, fat 0\n",
    "    \n",
    "    grid.fit(X, y) # fit the model and parameters\n",
    "    # our classical metric for performance\n",
    "    print(\"Best Accuracy: {}\".format(grid.best_score_))\n",
    "    # the best parameters that caused the best accuracy\n",
    "    print(\"Best Parameters: {}\".format(grid.best_params_))\n",
    "    # the average time it took a model to fit to the data (in seconds)\n",
    "    avg_time_fit = round(grid.cv_results_['mean_fit_time'].mean(), 3)\n",
    "    print(\"Average Time to Fit (s): {}\".format(avg_time_fit))\n",
    "    # the average tiem it took a model to predict out of sample data (in seconds)\n",
    "    # this metric gives us insight into how this model will perform in real-time analysis\n",
    "    print(\"Average Time to Score (s): {}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our function set up to take in models and parameters, let's use it to test our pipeline with our combinations of scaling, PCA, LDA, and KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9866666666666667\n",
      "Best Parameters: {'clf__n_neighbors': 3, 'preprocessing__lda__n_components': 2, 'preprocessing__pca__n_components': 3, 'preprocessing__scale__with_mean': True, 'preprocessing__scale__with_std': False}\n",
      "Average Time to Fit (s): 0.001\n",
      "Average Time to Score (s): 0.001\n"
     ]
    }
   ],
   "source": [
    "iris_params = {\n",
    "    'preprocessing__scale__with_std': [True, False],\n",
    "    'preprocessing__scale__with_mean': [True, False],\n",
    "    'preprocessing__pca__n_components': [1, 2, 3, 4],\n",
    "    'preprocessing__lda__n_components': [1, 2],\n",
    "    \n",
    "    'clf__n_neighbors': range(1, 9)\n",
    "}\n",
    "\n",
    "# make a larger pipeline\n",
    "preprocessing = Pipeline([('scale', StandardScaler()), ('pca', PCA()), ('lda', LinearDiscriminantAnalysis()), ('clf', KNeighborsClassifier())])\n",
    "\n",
    "#iris_pipeline = Pipeline(steps=[('preprocessing', preprocessing), ('clf', KNeighborsClassifier())])\n",
    "\n",
    "get_best_model_and_accuracy(iris_pipeline, iris_params, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy so far (near 99%) uses a combination of scaling, PCA, and LDA. It is common to correctly use all three of these algorithms in the same pipelines and perform hyper-parameter tuning to fine-tune the process. This shows us that more often than not, the best production-ready machine learning pipelines are in fact a combination of multiple feature engineering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References and credits to\n",
    "# Feature Engineering Made Easy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
